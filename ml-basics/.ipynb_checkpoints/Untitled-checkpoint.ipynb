{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cd9c3b4-9954-490a-bb0e-eb1312823654",
   "metadata": {},
   "source": [
    "# TOKENIZATION , LEMMATIZATION , SERIALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37b2cd9-9d15-487c-b884-5a91d20dfd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to use nltk library for building python programs to work with human language data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11da58ed-ce11-4a8e-85dc-c3341245f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aio\\anaconda3\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\aio\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\aio\\anaconda3\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\aio\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aio\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\aio\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d5aaa15-3849-410a-9efe-5515258564a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome to the world of GenAI. This is gonna be the future.\n",
      "2025 is going to be the future of AI.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# defining your own corpus\n",
    "\n",
    "corpus = \"\"\"Hello welcome to the world of GenAI. This is gonna be the future.\n",
    "2025 is going to be the future of AI.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89846b3a-aa77-4a6a-83c4-92d5348a3b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello welcome to the world of GenAI. This is gonna be the future.\n",
      "2025 is going to be the future of AI.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b063f77-ea14-4c25-939f-2b5912d4ad39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\AIO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bcbb3f6-0030-42b6-9db1-6db138153556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIO\\AppData\\Roaming\\nltk_data\\tokenizers\\punkt_tab\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.find(\"tokenizers/punkt_tab\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65862e7e-e5e0-49d8-9671-005a22bd2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My name is Rayyan Alam.', 'And I am 20 years old.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "text = \"My name is Rayyan Alam. And I am 20 years old.\"\n",
    "print(sent_tokenize(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7b0b1a-aeba-4088-91cc-f28314a9ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus  = \"\"\"Hello! my name is Rayyan Alam. I a getting my hands dirty on GenAI. 2025 is going to be\n",
    "    the year of AI.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f93bd50-14d7-45af-98c9-b6b1e39e57f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! my name is Rayyan Alam. I a getting my hands dirty on GenAI. 2025 is going to be\n",
      "    the year of AI.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Hello!',\n",
       " 'my name is Rayyan Alam.',\n",
       " 'I a getting my hands dirty on GenAI.',\n",
       " '2025 is going to be\\n    the year of AI.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corpus)\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sent_tokenize(corpus)\n",
    "\n",
    "# Notedown : it is toekinizing on the basis of exclamation marks too, along with the \n",
    "#           full stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4c659-5299-4094-a788-920267598918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hello just checking if this got saved"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
